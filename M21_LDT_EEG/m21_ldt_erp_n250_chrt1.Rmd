---
title: "M21 LDT ERP  N250"
author: "Joanna Morris"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 4
editor_options: 
  chunk_output_type: inline
---

\scriptsize

# Set parameters {-}
Set chunk parameters
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      comment = "||")
```

Load libraries
```{r, echo=FALSE}
library(tidyverse)
library(ggeffects)
library(lme4)
library(afex)
library(gridExtra)
library(emmeans)
library(effectsize)
library(performance)
library(cowplot)  # for use with `plot_grid(x,x,ncol = x)` function
library(e1071) # for use with `skewness()` function
```


Set ggplot parameters
```{r, echo=FALSE}
theme_set(theme_classic() +  
            theme(legend.position = "bottom", 
                  axis.text=element_text(size=10),
                  axis.title=element_text(size=9)))

# Define a custom color palette
my_palette <- c("#A6CEE3",  "#FB9A99")
my_palette_2 <- c( "#1F78B4","#E31A1C" )
my_palette_3 <- c("#A6CEE3","#1F78B4","#FB9A99","#E31A1C")


# Create a function to apply this palette
scale_color_custom <- function() {
  scale_color_manual(values = my_palette_2)
}

scale_fill_custom <- function() {
  scale_fill_manual(values = my_palette_2)
}
```


Define standard error of the mean function
```{r, echo=FALSE}
sem <- function(x) sd(x)/sqrt(length(x))
```

# N250 
## Load and format data files 

```{r}
erpdat_1 <- read_csv("m21_ldt_mea_200300_050050_1.csv")
dmg_lng_vsl <- read_csv("demo_lang_vsl_pca.csv")
```


Now we extract `SubjID` from the `ERPset` column
```{r}

# Remove '_LDT_diff_waves' from each string in the ERPset column
# This code first renames the column and then applies the `str_replace` function 
# to the newly renamed column.
erpdat_1 <- erpdat_1 %>%
  rename(SubjID = ERPset) %>%
  mutate(SubjID = str_replace(SubjID, "_LDT_diff_waves", "")) |>
  mutate(binlabel = str_replace(binlabel, "Critical_", "")) |>
  mutate(binlabel = str_replace(binlabel, "_family", "")) |>
  select(-mlabel)
```

We then join the ERP data and language into a single data frame
```{r}

n250_1 <- erpdat_1 |>
  left_join(dmg_lng_vsl, by = "SubjID") |>
  select(SubjID, everything()) |>
  rename(orthographic_sensitivity = lang_type_ortho)
```

Divide into word, non-word and difference wave dataframes
```{r, echo=FALSE}
n250_1_words <- n250_1 |> filter(bini %in% c(1:2))
n250_1_words_b <- n250_1 |> filter(bini %in% c(9:12))
n250_1_nonwords <- n250_1 |> filter(bini %in% c(3:6))
```

Then we do some more formatting and cleanup of the dataframes.We  create separate columns, one for each independent variable (anteriority, laterality, morphological family size). To do this we have to use `seperate` function from the `stringr` package. Run `vignette("programming", package = "dplyr")` to see more about `tidy-selection` and `tidy-evaluation`.

```{r}
# Words
n250_1_words <- n250_1_words %>%
  separate(binlabel, into = c("trial_type","family_size"), sep = "_", remove = TRUE) |>
  select(-trial_type)

n250_1_words_b <- n250_1_words_b %>%
  separate(binlabel, into = c("trial_type", "family_size","tmp1", "base_freq", "tmp2"), sep = "_", remove = TRUE) |>
  select(-c(trial_type, tmp1, tmp2))

# Assuming your data frame is named 'df' and the column is named 'your_column'
n250_1_words_b$orthographic_sensitivity[n250_1_words_b$orthographic_sensitivity == "Low"] <- "Low Sensitivity"
n250_1_words_b$orthographic_sensitivity[n250_1_words_b$orthographic_sensitivity == "High"] <- "High Sensitivity"
n250_1_words_b$base_freq[n250_1_words_b$base_freq == "Low"] <- "Low Base Frequency"
n250_1_words_b$base_freq[n250_1_words_b$base_freq == "High"] <- "High Base Frequency"
n250_1_words_b$family_size[n250_1_words_b$family_size == "large"] <- "Large Family"
n250_1_words_b$family_size[n250_1_words_b$family_size == "small"] <- "Small Family"

# Nonwords
n250_1_nonwords <- n250_1_nonwords %>%
  separate(binlabel, into = c("trial_type", "family_size", "complexity"), sep = "_", remove = TRUE) |>
  select(-trial_type)

# Assuming your data frame is named 'df' and the column is named 'your_column'
n250_1_nonwords$orthographic_sensitivity[n250_1_nonwords$orthographic_sensitivity == "Low"] <- "Low Sensitivity"
n250_1_nonwords$orthographic_sensitivity[n250_1_nonwords$orthographic_sensitivity == "High"] <- "High Sensitivity"
n250_1_nonwords$complexity[n250_1_nonwords$complexity == "complex"] <- "Complex"
n250_1_nonwords$complexity[n250_1_nonwords$complexity == "simple"] <- "Simple"
n250_1_nonwords$family_size[n250_1_nonwords$family_size == "large"] <- "Large Family"
n250_1_nonwords$family_size[n250_1_nonwords$family_size == "small"] <- "Small Family"

```

Now we need to  extract just the bins and channels that we intend to analyse. For this analysis we will use 9 channels:  F3, Fz, F4, C3, Cz, C4, P3, Pz, P4 . We will use the`mutate` function from the `dplyr` package along with the `case_when` function. The `case_when` function  is a sequence of two-sided formulas. The left hand side determines which values match this case. The right hand side provides the replacement value.

```{r}

channels_1 <-  c(3, 2, 25, 7, 20, 21, 12, 11, 16)
channels_2 <-  c(3, 2, 29, 8, 23, 24, 14, 13, 19)

# Words
n250_1_words <- n250_1_words %>%
  filter(chindex %in% channels_1) %>% 
  mutate(anteriority = case_when(grepl("F", chlabel) ~ "Frontal", 
                                 grepl("C", chlabel) ~ "Central",
                                 grepl("P", chlabel) ~ "Parietal"),
         laterality = case_when(grepl("3", chlabel) ~ "Left",grepl("z", chlabel) ~ "Midline",
                                grepl("Z", chlabel) ~ "Midline",grepl("4", chlabel) ~ "Right"))
n250_1_words$anteriority <- factor(n250_1_words$anteriority, levels = c("Frontal",  "Central",  "Parietal"))
n250_1_words$laterality <- factor(n250_1_words$laterality, levels = c("Left", "Midline", "Right"))

n250_1_words_b <- n250_1_words_b %>%
  filter(chindex %in% channels_1) %>% 
  mutate(anteriority = case_when(grepl("F", chlabel) ~ "Frontal", 
                                 grepl("C", chlabel) ~ "Central",
                                 grepl("P", chlabel) ~ "Parietal"),
         laterality = case_when(grepl("3", chlabel) ~ "Left",grepl("z", chlabel) ~ "Midline",
                                grepl("Z", chlabel) ~ "Midline",grepl("4", chlabel) ~ "Right"))
n250_1_words_b$anteriority <- factor(n250_1_words_b$anteriority, levels = c("Frontal",  "Central",  "Parietal"))
n250_1_words_b$laterality <- factor(n250_1_words_b$laterality, levels = c("Left", "Midline", "Right"))

# Nonwords
n250_1_nonwords <- n250_1_nonwords %>%
  filter(chindex %in% channels_1) %>% 
  mutate(anteriority = case_when(grepl("F", chlabel) ~ "Frontal",
                                 grepl("C", chlabel) ~ "Central", 
                                 grepl("P", chlabel) ~ "Parietal"),
         laterality = case_when(grepl("3", chlabel) ~ "Left",grepl("z", chlabel) ~ "Midline",
                                grepl("Z", chlabel) ~ "Midline", grepl("4", chlabel) ~ "Right"))
n250_1_nonwords$anteriority <- factor(n250_1_nonwords$anteriority, levels = c("Frontal",  "Central","Parietal"))
n250_1_nonwords$laterality <- factor(n250_1_nonwords$laterality, levels = c("Left", "Midline", "Right"))



```

## Real Word Data

### Compute the ANOVA
```{r}
anova_model_1a <- mixed(
  value ~ orthographic_sensitivity * family_size * base_freq  + 
    laterality * anteriority  +  # Nuisance variables
    (1 | SubjID), 
  data = n250_1_words_b, 
  method = "KR")  # Kenward-Roger approximation for accurate F-tests
# Print ANOVA results
anova_model_1a


# Partial Eta Squared
# Extract effect sizes from your ANOVA model
eta_squared(anova_model_1a , partial = TRUE)

# Compute Marginal (fixed effects) and Conditional (fixed + random effects) R²
r2(anova_model_1a)
```
### Significant Effects

|                            Effect|      df|         F| p.value||eta-sqrd|  
|----------------------------------|--------|----------|--------|---------|
|                       family_size| 1, 2121|   8.56 **|    .003|4.02e-03 | 
|                         base_freq| 1, 2121|   6.67 **|    .010|3.13e-03 |
|orthographic_sensitivity:base_freq| 1, 2121|    4.12 *|    .043|1.94e-03 |
|             family_size:base_freq| 1, 2121| 14.76 ***|   <.001|6.91e-03 |



```{r}
## `family_size` main effect
pairs <- emmeans(anova_model_1a, pairwise ~ family_size, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df <- as.data.frame(pairs$contrasts))
cohensd <- as.data.frame(cohens_d(value ~ family_size, data = n250_1_words_b))
(family_size_contrasts_df <- bind_cols(pairs_df,cohensd))
(family_size_means <- as.data.frame(pairs$emmeans))

## `base_freq` main effect
pairs <- emmeans(anova_model_1a, pairwise ~ base_freq, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df <- as.data.frame(pairs$contrasts))
cohensd <- as.data.frame(cohens_d(value ~ base_freq, data = n250_1_words_b))
(base_freq_contrasts_df <- bind_cols(pairs_df,cohensd))
(base_freq_means <- as.data.frame(pairs$emmeans))
```


```{r}
# Test whether the interaction between orthographic_sensitivity and base_freq improves model fit
reduced_model_int <- update(anova_model_1a,
  . ~ . - orthographic_sensitivity:base_freq - orthographic_sensitivity:family_size:base_freq)

anova(anova_model_1a, reduced_model_int)

# Custom contrasts for orthographic_sensitivity × base_freq Interaction
pairs <- emmeans(anova_model_1a, pairwise ~ orthographic_sensitivity * base_freq, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df <- as.data.frame(pairs$contrasts))

selected_contrasts_basefrq <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity High Base Frequency - High Sensitivity Low Base Frequency",
                                                                       "Low Sensitivity High Base Frequency - Low Sensitivity Low Base Frequency"),]
selected_contrasts_sensit <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity High Base Frequency - Low Sensitivity High Base Frequency",
                                                                      "Low Sensitivity High Base Frequency - High Sensitivity Low Base Frequency"), ]

selected_contrasts_basefrq_df <- as.data.frame(selected_contrasts_basefrq)  # Convert the emmGrid object to a dataframe
selected_contrasts_sensit_df <- as.data.frame(selected_contrasts_sensit)  

cohensd_hi_basefrq <- as.data.frame(cohens_d(value ~ orthographic_sensitivity,
                                          data = subset(n250_1_words_b, base_freq == "High Base Frequency")))
cohensd_lo_basefrq <- as.data.frame(cohens_d(value ~ orthographic_sensitivity, 
                                             data = subset(n250_1_words_b, base_freq == "Low Base Frequency")))
cohensd_hi_sensit <- as.data.frame(cohens_d(value ~ base_freq, 
                                            data = subset(n250_1_words_b, orthographic_sensitivity == "High Sensitivity")))
cohensd_lo_sensit <- as.data.frame(cohens_d(value ~ base_freq,
                                           data = subset(n250_1_words_b, orthographic_sensitivity == "Low Sensitivity")))

cohensd_basefrq <- bind_rows(hi_basefrq = cohensd_hi_basefrq,
                             lo_basefrq = cohensd_lo_basefrq,
                             .id = "base_freq")

cohensd_sensit <- bind_rows(hi_sensit = cohensd_hi_sensit,
                            lo_sensi = cohensd_lo_sensit,
                             .id = "sensitivity")

(basefreq_contrasts_df <- bind_cols(selected_contrasts_basefrq_df,cohensd_basefrq))
(sensitivity_contrasts_df <- bind_cols(selected_contrasts_sensit_df,cohensd_sensit))
(sensitivity.basefreq_means <- as.data.frame(pairs$emmeans))
```


###  Plots

N250 Amplitude by *Stem Base Frequency* & *Morphological Family Size*

```{r, echo=FALSE, fig.width=7, fig.height=3}
p1 <- ggplot(base_freq_means, aes(x = base_freq, y = emmean, fill = base_freq, colour = base_freq)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = .4) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE),
                width = 0.05, position = position_dodge(0.9)) +
  ylab("Mean ERP Amplitude (microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)), colour = "black", size = 2.5, vjust = -12,
            position = position_dodge(.9)) +
  scale_color_custom() +
  scale_fill_custom() +
  labs(title = "Base Frequency") +
  theme( plot.title = element_text(size = 10, hjust = 0.5),
         legend.position = "none",
         axis.title.x = element_blank(),
         axis.text.x = element_text(size = 8))

p2 <- ggplot(family_size_means, aes(x = family_size, y = emmean, fill = family_size, colour = family_size)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = .4) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE),
                width = 0.05, position = position_dodge(0.9)) +
  ylab("Mean ERP Amplitude (microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)), colour = "black", size = 2.5, vjust = -12,
            position = position_dodge(.9)) +
  scale_color_custom() +
  scale_fill_custom() +
  labs(title = "Morphological Family Size") +
  theme( plot.title = element_text(size = 10, hjust = 0.5),
         legend.position = "none",
         axis.title.x = element_blank(),
         axis.text.x = element_text(size = 8))

plot_grid(p1, p2, ncol = 2)

# combined_plot <- plot_grid(p1, p2, ncol = 2)
# (combined_plot_with_title <- combined_plot +
#   ggtitle("N250 Amplitude by Stem Base Frequency & Morphological Family Size") +
#   theme(plot.title = element_text(hjust = 0.5)))

```


```{r,  echo=FALSE, fig.width=5, fig.height=3.5}

p3 <- sensitivity.basefreq_means|>
  ggplot(aes(x = orthographic_sensitivity,
             y = emmean,
             fill = base_freq,
             colour = base_freq)) +
  geom_col(alpha = .4, position = position_dodge(.9)) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = .15,
                position = position_dodge(.9)) +
  labs(y="Mean ERP amplitude (in microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)),
                colour = "black",size = 2.5, vjust = -1.7, position = position_dodge(.65)) +
  scale_color_custom() +
  scale_fill_custom() +
  labs(title = "Orthographic Sensitivity x Base Frequency") +
  theme( plot.title = element_text(size = 10, hjust = 0.5),
         legend.title = element_blank(),
         axis.title.x = element_blank(),
         axis.text.x = element_text(size = 8))
p3
```

## Nonword Data

### Compute the ANOVA

```{r}

# Fit the ANOVA/mixed model
anova_model_1b <- mixed(
  value ~ orthographic_sensitivity * family_size * complexity + 
    laterality * anteriority  +  # Nuisance variables
    (1 | SubjID), 
  data = n250_1_nonwords, 
  method = "KR"  # Kenward-Roger approximation for accurate F-tests
)

# Print ANOVA results
anova_model_1b 

# Partial Eta Squared
# Extract effect sizes from your ANOVA model
eta_squared(anova_model_1b , partial = TRUE)

# Compute Marginal (fixed effects) and Conditional (fixed + random effects) R²
r2(anova_model_1b)
```

### Effects

  |Effect                                   |df          |F       |p     |eta-sqrd|
  |-----------------------------------------|------------|--------|------|--------|
  |orthographic_sensitivity x family_size   |(1, 2121)   |3.55 *  |.060  |1.67e-03| 
  |orthographic_sensitivity x complexity    |(1, 2121)   |5.15 *  |.023  |2.42e-03|




```{r}
# Test whether the interaction between orthographic_sensitivity and complexity improves model fit
reduced_model_int <- update(anova_model_1b,
  . ~ . - orthographic_sensitivity:family_size - orthographic_sensitivity:family_size:complexity)

anova(anova_model_1b, reduced_model_int)

# Custom contrasts for orthographic_sensitivity × family_size (Interaction)

pairs <- emmeans(anova_model_1b, pairwise ~ orthographic_sensitivity * family_size, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df <- as.data.frame(pairs$contrasts))

selected_contrasts_famsize <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity Large Family - High Sensitivity Small Family",
                                                               "Low Sensitivity Large Family - Low Sensitivity Small Family"),]
selected_contrasts_sensit <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity Large Family - Low Sensitivity Large Family ",
                                                                       "High Sensitivity Small Family - Low Sensitivity Small Family"), ]

selected_contrasts_df_famsize <- as.data.frame(selected_contrasts_famsize)  # Convert the emmGrid object to a dataframe
selected_contrasts_df_sensit <- as.data.frame(selected_contrasts_sensit)  # Convert the emmGrid object to a dataframe

cohensd_small <- as.data.frame(cohens_d(value ~ orthographic_sensitivity, 
         data = subset(n250_1_nonwords, family_size == "Small Family")))
cohensd_large <- as.data.frame(cohens_d(value ~ orthographic_sensitivity, 
         data = subset(n250_1_nonwords, family_size == "Large Family")))
cohensd_hi_sensit <- as.data.frame(cohens_d(value ~ family_size, 
         data = subset(n250_1_nonwords, orthographic_sensitivity == "High Sensitivity")))
cohensd_lo_sensit <- as.data.frame(cohens_d(value ~ family_size, 
         data = subset(n250_1_nonwords, orthographic_sensitivity == "Low Sensitivity")))

cohensd_sensit <- bind_rows(large = cohensd_large,
                             small = cohensd_small,
                             .id = "famsize")

cohensd_famsize <- bind_rows(hi_ortho = cohensd_hi_sensit,
                             lo_ortho = cohensd_lo_sensit,
                             .id = "sensit")

(sensit_contrasts_df <- bind_cols(selected_contrasts_df_sensit,cohensd_sensit))
(famsize_contrasts_df <- bind_cols(selected_contrasts_df_famsize,cohensd_famsize))
(sensit.famsize_means <- as.data.frame(pairs$emmeans))
```



```{r}
# Test whether the interaction between orthographic_sensitivity and complexity improves model fit
reduced_model_int <- update(anova_model_1b,
  . ~ . - orthographic_sensitivity:complexity - orthographic_sensitivity:family_size:complexity)

anova(anova_model_1b, reduced_model_int)

# Custom contrasts for lang_type_ortho × complexity (Interaction) 
pairs <- emmeans(anova_model_1b, pairwise ~ orthographic_sensitivity * complexity, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df <- as.data.frame(pairs$contrasts))

selected_contrasts_cmplxty <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity Complex - High Sensitivity Simple",
                                                                       "Low Sensitivity Complex - Low Sensitivity Simple"),]
selected_contrasts_sensit <- pairs$contrasts[pairs_df$contrast %in% c("High Sensitivity Complex - Low Sensitivity Complex",
                                                                      "High Sensitivity Simple - Low Sensitivity Simple"), ]

selected_contrasts_df_cmplxty <- as.data.frame(selected_contrasts_cmplxty)  # Convert the emmGrid object to a dataframe
selected_contrasts_df_sensit  <- as.data.frame(selected_contrasts_sensit)  

cohensd_complex <- as.data.frame(cohens_d(value ~ orthographic_sensitivity, 
         data = subset(n250_1_nonwords, complexity == "Complex")))
cohensd_simple <- as.data.frame(cohens_d(value ~ orthographic_sensitivity, 
         data = subset(n250_1_nonwords, complexity == "Simple")))
cohensd_hi_sensit <- as.data.frame(cohens_d(value ~ complexity, 
         data = subset(n250_1_nonwords, orthographic_sensitivity == "High Sensitivity")))
cohensd_lo_sensit <- as.data.frame(cohens_d(value ~ complexity, 
         data = subset(n250_1_nonwords, orthographic_sensitivity == "Low Sensitivity")))

cohensd_sensit <- bind_rows(complex = cohensd_complex,
                             simple = cohensd_simple,
                             .id = "sensitivity")

cohensd_cmplxty <- bind_rows(hi_sensit= cohensd_hi_sensit,
                             lo_sensit = cohensd_lo_sensit,
                             .id = "complexity")

(sensit_contrasts_df <- bind_cols(selected_contrasts_df_sensit,cohensd_sensit))
(cmplxty_contrasts_df <- bind_cols(selected_contrasts_df_cmplxty,cohensd_cmplxty))
(sensit.cmplxty_means <- as.data.frame(pairs$emmeans))
```

### Plots 
...

```{r,  echo=FALSE}
p1 <- sensit.famsize_means|>
  ggplot(aes(x = orthographic_sensitivity,
             y = emmean,
             fill = family_size,
             colour = family_size)) +
  geom_col(alpha = .4, position = position_dodge(.9)) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = .15,
                position = position_dodge(.9)) +
  labs(y="Mean ERP amplitude (in microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)),
                colour = "black",size = 2.5, vjust = -1.7, position = position_dodge(.65)) +
  scale_color_custom() +
  scale_fill_custom() +
  labs(title = "Orthographic Sensitivity x Family Size") +
  theme( plot.title = element_text(size = 10, hjust = .5),
         legend.title = element_blank(),
         axis.title.x = element_blank(),
         axis.text.x = element_text(size = 8))
#p1
```
...

```{r,  echo=FALSE, fig.width=7, fig.height=3.5}

p2 <- sensit.cmplxty_means|>
  ggplot(aes(x = orthographic_sensitivity,
             y = emmean,
             fill = complexity,
             colour = complexity)) +
  geom_col(alpha = .4, position = position_dodge(.9)) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = .15,
                position = position_dodge(.9)) +
  labs(y="Mean ERP amplitude (in microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)),
                colour = "black",size = 2.5, vjust = -1.7, position = position_dodge(.6)) +
  scale_color_custom() +
  scale_fill_custom() +
  labs(title = "Orthographic Sensitivity x Complexity") +
  theme(  plot.title = element_text(size = 10, hjust = .5),
         legend.title = element_blank(),
         axis.title.x = element_blank(),
         axis.text.x = element_text(size = 8))
#p2
plot_grid(p1, p2, ncol = 2)
```


