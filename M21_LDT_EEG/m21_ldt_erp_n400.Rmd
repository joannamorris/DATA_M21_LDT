---
title: "m21 LDT ERP analysis N400"
author: "Joanna Morris"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 4
editor_options: 
  chunk_output_type: inline
---

\scriptsize

# Set parameters
Set chunk parameters
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      comment = "||")
```

Load libraries
```{r}
library(performance)
library(effectsize)
library(afex)
library(emmeans)
library(gridExtra)
library(kableExtra)
library(pander)
library(tidyverse)
```


Set ggplot parameters
```{r}
theme_set(theme_classic() +  
            theme(legend.position = "bottom", 
                  axis.text=element_text(size=10),
                  axis.title=element_text(size=9)))

# Define a custom color palette
my_palette <- c("#A6CEE3",  "#FB9A99")
my_palette_2 <- c( "#1F78B4","#E31A1C" )
my_palette_3 <- c("#A6CEE3","#1F78B4","#FB9A99","#E31A1C")


# Create a function to apply this palette
scale_color_custom <- function() {
  scale_color_manual(values = my_palette_2)
}

scale_fill_custom <- function() {
  scale_fill_manual(values = my_palette_2)
}
```


Define standard error of the mean function
```{r}
sem <- function(x) sd(x)/sqrt(length(x))
```


# Load and format data files

```{r, echo = FALSE}
erpdat_1 <- read_csv("m21_ldt_mea_300500_050050_1.csv")
erpdat_2 <- read_csv("m21_ldt_mea_300500_050050_2.csv")
dmg_lng_vsl <- read_csv("demo_lang_vsl_pca.csv")

```

Now we extract `SubjID` from the `ERPset` column
```{r, echo = FALSE}

# Remove '_LDT_diff_waves' from each string in the ERPset column
# This code first renames the column and then applies the `str_replace` function 
# to the newly renamed column.
erpdat_1 <- erpdat_1 %>%
  rename(SubjID = ERPset) %>%
  mutate(SubjID = str_replace(SubjID, "_LDT_diff_waves", "")) |>
  mutate(binlabel = str_replace(binlabel, "Critical_", "")) |>
  mutate(binlabel = str_replace(binlabel, "_family", "")) |>
  select(-mlabel)

erpdat_2 <- erpdat_2 %>%
  rename(SubjID = ERPset) %>%
  mutate(SubjID = str_replace(SubjID, "_LDT_diff_waves", "")) |>
  mutate(binlabel = str_replace(binlabel, "Critical_", "")) |>
  mutate(binlabel = str_replace(binlabel, "_family", ""))|>
  select(-mlabel)
```

We then join the ERP data, and language into a single data frame
```{r, echo = FALSE}

n400_1 <- erpdat_1 |>
  left_join(dmg_lng_vsl, by = "SubjID") |>
  select(SubjID, everything())

n400_2 <- erpdat_2 %>%
  full_join(dmg_lng_vsl, by = "SubjID") |>
  select(SubjID, everything())

```

Divide into word, non-word and difference wave dataframes
```{r}
n400_1_words <- n400_1 |> filter(bini %in% c(1:2))
n400_1_nonwords <- n400_1 |> filter(bini %in% c(3:6))
n400_1_diff <- n400_1 |> filter(bini %in% c(9:11))

n400_2_words <- n400_2 |> filter(bini %in% c(1:2))
n400_2_nonwords <- n400_2 |> filter(bini %in% c(3:6))
n400_2_diff <- n400_2 |> filter(bini %in% c(9:11))
```

Then we do some more formatting and cleanup of the dataframes.We  create separate columns, one for each independent variable (anteriority, laterality, morphological family size). To do this we have to use `seperate` function from the `stringr` package. Run `vignette("programming", package = "dplyr")` to see more about `tidy-selection` and `tidy-evaluation`.

```{r, echo = FALSE}
n400_1_nonwords <- n400_1_nonwords %>%
  separate(binlabel, into = c("trial_type", "family_size", "complexity"), sep = "_", remove = TRUE) |>
  select(-trial_type)
n400_1_words <- n400_1_words %>%
  separate(binlabel, into = c("trial_type", "family_size"), sep = "_", remove = TRUE) |>
  select(-trial_type)

n400_2_nonwords <- n400_2_nonwords %>%
  separate(binlabel, into = c("trial_type", "family_size", "complexity"), sep = "_", remove = TRUE) |>
  select(-trial_type)
n400_2_words <- n400_2_words %>%
  separate(binlabel, into = c("trial_type", "family_size"), sep = "_", remove = TRUE) |>
  select(-trial_type)

n400_1_diff <- n400_1_diff |> 
    mutate(binlabel = str_replace(binlabel, "_Small_Minus_Large_Family_Size", "")) 
n400_2_diff <- n400_2_diff |> 
    mutate(binlabel = str_replace(binlabel, "_Small_Minus_Large_Family_Size", "")) 
  
```

Now we need to  extract just the bins and channels that we intend to analyse. For this analysis we will use 9 channels:  F3, Fz, F4, C3, Cz, C4, P3, Pz, P4 . We will use the`mutate` function from the `dplyr` package along with the `case_when` function. The `case_when` function  is a sequence of two-sided formulas. The left hand side determines which values match this case. The right hand side provides the replacement value.

```{r, echo=FALSE}

channels_1 <-  c(3, 2, 25, 7, 20, 21, 12, 11, 16)
channels_2 <-  c(3, 2, 29, 8, 23, 24, 14, 13, 19)

n400_1_nonwords <- n400_1_nonwords %>%
  filter(chindex %in% channels_1) %>% 
  mutate(anteriority = case_when(grepl("F", chlabel) ~ "Frontal",
                                 grepl("C", chlabel) ~ "Central",
                                 grepl("P", chlabel) ~ "Parietal"),
         laterality = case_when(grepl("3", chlabel) ~ "Left",
                                grepl("z", chlabel) ~ "Midline",
                                grepl("Z", chlabel) ~ "Midline",
                                grepl("4", chlabel) ~ "Right"))
n400_1_nonwords$anteriority <- factor(n400_1_nonwords$anteriority, levels = c("Frontal", 
                                                                              "Central", 
                                                                              "Parietal"))
n400_1_nonwords$laterality <- factor(n400_1_nonwords$laterality, levels = c("Left", 
                                                                            "Midline", 
                                                                            "Right"))


n400_2_nonwords <- n400_2_nonwords %>%
  filter(chindex %in% channels_2) %>% 
  mutate(anteriority = case_when(grepl("F", chlabel) ~ "Frontal",
                                 grepl("C", chlabel) ~ "Central",
                                 grepl("P", chlabel) ~ "Parietal"),
         laterality = case_when(grepl("3", chlabel) ~ "Left",
                                grepl("z", chlabel) ~ "Midline",
                                grepl("Z", chlabel) ~ "Midline",
                                grepl("4", chlabel) ~ "Right"))
n400_2_nonwords$anteriority <- factor(n400_2_nonwords$anteriority, levels = c("Frontal", 
                                                                              "Central", 
                                                                              "Parietal"))
n400_2_nonwords$laterality <- factor(n400_2_nonwords$laterality, levels = c("Left", 
                                                                            "Midline", 
                                                                            "Right"))
n400_2_nonwords$anteriority <- factor(n400_2_nonwords$anteriority, levels = c("Frontal", 
                                                                              "Central", 
                                                                              "Parietal"))
n400_2_nonwords$laterality <- factor(n400_2_nonwords$laterality, levels = c("Left", 
                                                                            "Midline", 
                                                                            "Right"))

```

# Compute the ANOVA

A linear mixed-effects modeling approach was used to analyze ERP amplitudes in the n400 time window. This method offers several advantages over traditional repeated-measures ANOVA. First, it allows for accurate estimation of fixed effects by explicitly modeling nuisance variables such as Laterality and Anteriority, which account for a substantial proportion of the variance in ERP amplitude. Including these topographic covariates in the model improves the precision of estimates for the linguistic variables of interest. Second, mixed-effects models provide a more appropriate treatment of within-subject dependencies by estimating random effects for participants, thereby avoiding the sphericity assumptions required by repeated-measures ANOVA and allowing for unbalanced data without biasing results. Third, the use of planned contrasts and post hoc comparisons with Bonferroni correction helps control the family-wise error rate, reducing the risk of Type I error across multiple tests. Finally, by treating subjects as random effects, the model supports broader generalization of the findings beyond the specific sample tested. Together, these features make linear mixed-effects models well suited for analyzing ERP data with complex factorial designs and repeated observations.

## Group 1

### ANOVA Model 

```{r}

# Fit the ANOVA/mixed model
anova_model_1 <- mixed(
  value ~ lang_type_ortho * family_size * complexity + 
    laterality * anteriority  +  # Nuisance variables
    (1 | SubjID), 
  data = n400_1_nonwords, 
  method = "KR"  # Kenward-Roger approximation for accurate F-tests
)

# Print ANOVA results
anova_model_1
```

### Partial Eta Squared 

Compute Partial Eta Squared ($\eta_p^2$ ) for F-tests. This gives $\eta_p^2$  values for each effect.  Then, compute $R^2$ for the Mixed Model. This provides marginal $R^2$ (fixed effects only) and conditional $R^2$ (fixed + random effects).

```{r}
# Extract effect sizes from your ANOVA model
eta_squared(anova_model_1, partial = TRUE)

# Compute Marginal and Conditional R²
r2(anova_model_1)
```
### Main Findings

 No Significant Main Effects or Interactions



## Cohort 2

### ANOVA Model 
```{r}
# Fit the ANOVA/mixed model
anova_model_2 <- mixed(
  value ~ lang_type_ortho * family_size * complexity + 
    laterality * anteriority  +  # Nuisance variables
    (1 | SubjID), 
  data = n400_2_nonwords, 
  method = "KR"  # Kenward-Roger approximation for accurate F-tests
)

# Print ANOVA results
anova_model_2
```

### Compute Partial Eta Squared 

Compute Partial Eta Squared ($\eta_p^2$ ) for F-tests. This gives $\eta_p^2$  values for each effect.  Then, compute $R^2$ for the Mixed Model. This provides marginal $R^2$ (fixed effects only) and conditional $R^2$ (fixed + random effects).

```{r}
# Extract effect sizes from your ANOVA model
eta_squared(anova_model_2, partial = TRUE)

# Compute Marginal and Conditional R²
r2(anova_model_2)
```
### Main Findings

|Effect                          |df        |F        |p      |eta-sqrd|
|-------------------------------|-----------|---------|-------|--------|
|lang_type_ortho                |(1, 40  )  | 2.97   +| .093  |0.07    |    
|complexity                     |(1, 1456)  | 7.85  **| .005  |5.36e-03|
|family_size x complexity       |(1, 1456)  |10.08  **| .002  |6.88e-03|
|lang_type_ortho:complexity     |(1, 1456)  |2.72    +| .099  |1.87e-03|

Main effect of Complexity; Simple words are more negative than complex words from 200-300 ms.

#### Complexity (Main Effect)
#####  Cohen's d for Complexity (Main Effect)

```{r}
pairs_2 <- emmeans(anova_model_2, pairwise ~ complexity, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df_2 <- as.data.frame(pairs_2$contrasts))
cohensd_2 <- as.data.frame(cohens_d(value ~ complexity, data = n400_2_nonwords))
(complexity_contrasts_df_2 <- bind_cols(pairs_df_2,cohensd_2))
(complexity_means_2 <- as.data.frame(pairs_2$emmeans))
```


##### Mixed Model Comparison: Complexity

To test the effect of `Complexity`, we compare:

 - Full model (anova_model_2) → includes `Complexity` and all interactions.
 
 - Reduced model (reduced_model) → removes `Complexity` and all interactions involving `Complexity`


```{r}
reduced_model <- update(anova_model_2,
                        . ~ . - complexity - complexity:family_size - complexity:lang_type_ortho - complexity:family_size:lang_type_ortho)
anova(anova_model_2, reduced_model)
```

A model including Complexity and its interactions provided a significantly better fit than a model without it, $\chi^2(4) = 21.779$, $p < .001$, indicating that the complexity of words  modulates the ERP responses.





##### Plot for Complexity

Complexity

```{r, echo = FALSE}
p3 <- ggplot(complexity_means_2, aes(x = complexity, y = emmean, fill = complexity, colour = complexity)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = .4) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE),
                width = 0.05, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 2.5)) +
  ylab("Mean ERP Amplitude (microvolts)") +
  geom_text(aes(label = round(emmean, digits = 2)), colour = "black", size = 2.5, vjust = 12,
            position = position_dodge(.9)) +
  scale_color_custom() +
  scale_fill_custom()
p3
```

#### lang_type_ortho (Main Effect)
#####  Cohen's d for lang_type_ortho (Main Effect)

```{r}
pairs_2 <- emmeans(anova_model_2, pairwise ~ lang_type_ortho, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df_2 <- as.data.frame(pairs_2$contrasts))
cohensd_2 <- as.data.frame(cohens_d(value ~ lang_type_ortho, data = n400_2_nonwords))
(lngtyp_contrasts_df_2 <- bind_cols(pairs_df_2,cohensd_2))
(lngtyp_means_2 <- as.data.frame(pairs_2$emmeans))
```


##### Mixed Model Comparison: lang_type_ortho


```{r}
reduced_model <- update(anova_model_2,
                        . ~ . - lang_type_ortho - lang_type_ortho:family_size - complexity:lang_type_ortho - complexity:family_size:lang_type_ortho)
anova(anova_model_2, reduced_model)
```

A model including sensitivity to orthographic structure and its interactions provided a significantly better fit than a model without it, $\chi^2(4) = 21.779$, $p < .001$, indicating that the complexity of words  modulates the ERP responses.

##### Plot for lang_type_ortho

lang_type_ortho

```{r, echo = FALSE}
p2 <- ggplot(lngtyp_means_2, aes(x = lang_type_ortho, y = emmean, fill = lang_type_ortho, colour = lang_type_ortho)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = .4) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE),
                width = 0.05, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 2.5)) +
  ylab("Mean ERP Amplitude (microvolts)") +
  xlab("Sensitivity to Morpho-Orthographic Structure")
  geom_text(aes(label = round(emmean, digits = 2)), colour = "black", size = 2.5, vjust = 12,
            position = position_dodge(.9)) +
  scale_color_custom() +
  scale_fill_custom()
p2
```

#### family_size x complexity (Interaction) 

##### Custom contrasts for family_size x complexity (Interaction) 

```{r}
pairs_2 <- emmeans(anova_model_2, pairwise ~ complexity * family_size, adjust = "bonferroni", pbkrtest.limit = 6480)
(pairs_df_2 <- as.data.frame(pairs_2$contrasts))
selected_contrasts_famsize_2 <- pairs_2$contrasts[pairs_df_2$contrast %in% c("complex large - complex small",
                                                                             "simple large - simple small"),]
selected_contrasts_cmplxty_2 <- pairs_2$contrasts[pairs_df_2$contrast %in% c("complex small - simple small",
                                                                             "complex large - simple large"), ]
selected_contrasts_df_famsize_2 <- as.data.frame(selected_contrasts_famsize_2)
# Convert the emmGrid object to a dataframe
selected_contrasts_df_cmplxty_2 <- as.data.frame(selected_contrasts_cmplxty_2)
# Convert the emmGrid object to a dataframe
cohensd_small_2 <- as.data.frame(cohens_d(value ~ complexity, 
         data = subset(n400_2_nonwords, family_size == "small")))
cohensd_large_2 <- as.data.frame(cohens_d(value ~ complexity, 
         data = subset(n400_2_nonwords, family_size == "large")))
cohensd_complex_2 <- as.data.frame(cohens_d(value ~ family_size, 
         data = subset(n400_2_nonwords, complexity == "complex")))
cohensd_simple_2 <- as.data.frame(cohens_d(value ~ family_size, 
         data = subset(n400_2_nonwords, complexity == "simple")))

cohensd_famsize_2 <- bind_rows(complex = cohensd_complex_2,
                               simple = cohensd_simple_2,
                               .id = "cmplxty")

cohensd_cmplxty_2 <- bind_rows(large = cohensd_large_2,
                               small = cohensd_small_2,
                               .id = "famsize")



(cmplxty_contrasts_df_2 <- bind_cols(selected_contrasts_df_cmplxty_2,cohensd_cmplxty_2))
(famsize_contrasts_df_2 <- bind_cols(selected_contrasts_df_famsize_2,cohensd_famsize_2))
(famsize_cmplxty_means_2 <- as.data.frame(pairs_2$emmeans))

```

Plots for  family_size x complexity (Interaction)

```{r,  echo=FALSE}

p3 <- famsize_cmplxty_means_2|>
  ggplot(aes(x = family_size,
             y = emmean,
             fill = complexity,
             colour = complexity)) +
  geom_col(alpha = .4, position = position_dodge(.9)) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = .15,
                position = position_dodge(.9)) +
  coord_cartesian(ylim = c(0, 3)) +
  labs(y="Mean ERP amplitude (in microvolts)",
       x = "Morphological Family Size") +
  geom_text(aes(label = round(emmean, digits = 2)),
                colour = "black",size = 2.5, vjust = -1.7, position = position_dodge(.65)) +
  scale_color_custom() +
  scale_fill_custom()
p3
```
