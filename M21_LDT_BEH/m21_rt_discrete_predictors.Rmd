---
title: "m21_rt"
author: "Joanna Morris"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

\scriptsize

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      comment = "||",
                      fig.height = 4,
                      fig.width = 4)
options(width = 130)
```

# Setup  {-}

Load libraries
```{r, echo=FALSE}
library(tidyverse)
library(ggeffects)
library(lme4)
library(afex)
library(gridExtra)
library(emmeans)
library(effectsize)
library(performance)
library(cowplot)  # for use with `plot_grid(x,x,ncol = x)` function
library(e1071) # for use with `skewness()` function
library(lmerTest)
```


1. Set `ggplot2` parameters
```{r theme, echo = FALSE}
theme_set(theme_classic() +  
            theme(legend.position = "bottom", 
                  axis.text=element_text(size=8),
                  axis.title=element_text(size=9),
                  plot.title = element_text(size = 9),
                  plot.subtitle = element_text(size = 8)))

# Define a custom color palette
my_palette <- c("#1F78B4","#E31A1C", "#33A02C")
my_palette_1 <- c("#A6CEE3",  "#FB9A99")
my_palette_2 <- c( "#1F78B4","#E31A1C" )
my_palette_3 <- c("#A6CEE3","#1F78B4","#FB9A99","#E31A1C")



# Create a function to apply this palette
scale_color_custom <- function() {
  scale_color_manual(values = my_palette)
}

scale_fill_custom <- function() {
  scale_fill_manual(values = my_palette)
}

```

# Load Files and Format Files  {-}

## Load Files
```{r}
DIR <- "csv_files"
rt_1 <- read_csv(file.path(DIR, "rt_data_coh1.csv"))
frq_w <- read_csv(file.path(DIR, "frq_cw.csv"))
frq_nw <- read_csv(file.path(DIR, "frq_nw.csv"))
dmg <- read_csv(file.path(DIR, "demo_lang_vsl_pca_hc.csv"))
```


## Format Files
```{r}
# Concatenate datasets
# rt <- bind_rows(Hampshire = rt_1, 
#                 Providence =rt_2,
#                 .id = "location")
rt_dmg<- right_join(dmg, rt_1, join_by(SubjID == subject_nr)) |>  # Join Participant Demographic and Lang Data
                    mutate(target = tolower(target)) |>
                    filter(correct == 1)

# Divide into Experimental and Filler Items
rt_fill <- rt_dmg |> filter(str_detect(targ_type, "^FILL"))
rt_exp <- rt_dmg |> filter(!str_detect(targ_type, "^FILL"))

# Define Factors and Conditions
rt_exp_format <- rt_exp |>
  separate(targ_type, into = c("trial_type", "family_size", "complexity"), sep = "_",
           remove = TRUE, extra = "drop", fill = "right") 

# Divide into Words and Nonwords
rt_words <- rt_exp_format |> filter(trial_type == "CW") |> select(- complexity)
rt_nwords <- rt_exp_format |> filter(trial_type == "NW")

# Join Stimulus Frequency Data
rt_words_frq <- left_join(rt_words, frq_w, join_by(target))|>
  select(-cond_trig.y, -word_trig.y) |>
  rename(cond_trig = cond_trig.x, word_trig = word_trig.x)  # remove duplicate columns
rt_nwords_frq <-  left_join(rt_nwords, frq_nw, join_by(target==word))

# Rename BF_Split and FS_Split columns
rt_words_frq <- rt_words_frq |> rename(Base_Frequency = BF_Split, Family_Size = FS_Split) # Rename BF_Split and FS_Split columns
rt_nwords_frq <- rt_nwords_frq |> rename(Base_Frequency = BF_Split, Family_Size = FS_Split)

# Recode factor levels
rt_words_frq <- rt_words_frq |>
  mutate(Base_Frequency = case_match(Base_Frequency, "S" ~ "Low BF", "L" ~ "High BF"),
         Family_Size = case_match(Family_Size, "S" ~ "Small Family", "L" ~ "Large Family"))
rt_nwords_frq <- rt_nwords_frq |> mutate(Base_Frequency = case_match(Base_Frequency, "S" ~ "Low BF", "L" ~ "High BF"),
                                         Family_Size = case_match(Family_Size, "S" ~ "Small Family", "L" ~ "Large Family"))

rt_words_frq$Orthographic_Sensitivity[rt_words_frq$Orthographic_Sensitivity == "Low"] <- "Low Sensitivity"
rt_words_frq$Orthographic_Sensitivity[rt_words_frq$Orthographic_Sensitivity == "High"] <- "High Sensitivity"

# str(rt_words_1)
```

# Analyse Data

## Plot RT distributions
```{r, echo = FALSE, fig.width=7}
# RT boxplot
p1 <- rt_words_frq |> ggplot(aes(x = SubjID, y = response_time)) +
  geom_boxplot(colour = "#1F78B4", fill = "#1F78B4", alpha = .4 )+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Words")
p2 <- rt_nwords_frq |> ggplot(aes(x = SubjID, y = response_time)) +
  geom_boxplot(colour = "#E31A1C", fill = "#E31A1C", alpha = .4)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Non-words")
plot_grid(p1, p2, ncol = 2)

# RT density plot
p1 <- rt_words_frq |> ggplot(aes(x = response_time)) +
  geom_density(colour = "#1F78B4", fill = "#1F78B4", alpha = .4) +
  labs(title = "Words")
p2 <- rt_nwords_frq |> ggplot(aes(x = response_time)) +
  geom_density(colour = "#E31A1C", fill = "#E31A1C", alpha = .4) +
  labs(title = "Non-words")
plot_grid(p1, p2, ncol = 2)

```

## Test for Skewness

### Base Frequency
... 

```{r, echo=FALSE, fig.width=7}
# Raw BF
p1 <- ggplot(rt_words_frq, aes(x = BF)) +
  geom_density(colour = "#B2DF8A", fill = "#B2DF8A", alpha = .4) +
  labs(title = "Distribution of Raw Base Frequency")

# Log10BF
p2 <- ggplot(rt_words_frq, aes(x = Log10BF)) +
  geom_density(colour = "#33A02C", fill = "#33A02C", alpha = .4) +
  labs(title = "Distribution of Log10 Base Frequency")+
  scale_fill_custom() +
  scale_color_custom()

plot_grid(p1, p2, ncol = 2)

library(e1071)
# Skewness values
skewness(rt_words_frq$BF, na.rm = TRUE)
skewness(rt_words_frq$Log10BF, na.rm = TRUE)
```

### Family Size
... 

```{r}
# Skewness values

rt_words_frq <- rt_words_frq |> mutate(Log10FS = log10(FS))
skewness(rt_words_frq$FS, na.rm = TRUE)
skewness(rt_words_frq$Log10FS, na.rm = TRUE)

# Raw FS
p1 <- ggplot(rt_words_frq, aes(x = FS)) +
  geom_density(colour = "#B2DF8A", fill = "#B2DF8A", alpha = .4) +
  labs(title = "Distribution of Family Size")
# Log10 FS
p2 <- ggplot(rt_words_frq, aes(x = Log10FS)) +
  geom_density(colour = "#B2DF8A", fill = "#B2DF8A", alpha = .4) +
  labs(title = "Distribution of Log10 Family Size")

plot_grid(p1, p2, ncol = 2)
```

## ANOVA Words

Use `complete.cases()` to find which rows have missing data in the model-relevant variables:
```{r, echo=FALSE, results = "hide"}
# Specify only the variables used in the model
model_vars <- c("response_time",  "Log10BF","BF", "FS","Family_Size", "Base_Frequency", "Dim.2","SubjID")

# Identify incomplete rows cohort 1
incomplete_cases_words <- rt_words_frq[!complete.cases(rt_words_frq[, model_vars]), ]
rt_words_cmpl <- rt_words_frq[complete.cases(rt_words_frq[, model_vars]), ]
# View them
print(incomplete_cases_words)

# Standardize the predictors
rt_words_cmpl$Log10BF_std <- as.numeric(scale(rt_words_cmpl$Log10BF, center = TRUE, scale = TRUE))
rt_words_cmpl$FS_std <- as.numeric(scale(rt_words_cmpl$FS, center = TRUE, scale = TRUE))
rt_words_cmpl$Log10WF_std <- as.numeric(scale(rt_words_cmpl$Log10WF, center = TRUE, scale = TRUE))
rt_words_cmpl$Log10FS_std <- as.numeric(scale(rt_words_cmpl$Log10FS, center = TRUE, scale = TRUE))
rt_words_cmpl$Dim.2_std <- as.numeric(scale(rt_words_cmpl$Dim.2, center = TRUE, scale = TRUE))
```


```{r}
rt_words_cmpl %>%
  summarise(
    n_subjects = n_distinct(SubjID),
    n_items = n_distinct(STRING)
  )

# Count trials per subject
rt_words_cmpl %>%
  count(SubjID, name = "n_trials") %>%
  summarise(
    min_trials = min(n_trials),
    max_trials = max(n_trials),
    mean_trials = mean(n_trials)
  )

(trial_count_by_subj <- rt_words_cmpl %>%
  count(SubjID, name = "n_trials") %>%
  arrange(desc(n_trials)))

s124 <- rt_words_cmpl |> filter(SubjID == "S124")
```


```{r}
rt_words_cmpl %>%
  summarise(
    n_subjects = n_distinct(SubjID),
    n_items = n_distinct(Item)
  )
```

### Anova with Continuous Log10BF and Categorical FS

```{r}
anova_model_words <- mixed(
  response_time ~ Base_Frequency * Family_Size * Orthographic_Sensitivity + (1  | SubjID),
  data = rt_words_cmpl,
  method = "KR")
anova_model_words

m1 <- anova_model_words$full_model    # Extract the lmer model
ranova(m1) # Run random effects comparison
```

```{r}
anova_model_words_2 <- mixed(
  response_time ~ Base_Frequency * Family_Size * Orthographic_Sensitivity +
    (1 | SubjID) +
    (1 | STRING),
  data = rt_words_cmpl,
  method = "S")
anova_model_words_2
```


#### Main Findings:

|                        Effect|         df |       F |p.value |
|------------------------------|------------|---------|--------|
|                Base_Frequency| 1, 5792.69 |37.15 ***|   <.001|
|                   Family_Size| 1, 5792.31 |45.05 ***|   <.001|
|    Base_Frequency:Family_Size| 1, 5792.69 |   6.92 *|    .009|
	

#### Plots

Plotting Processing Efficiency

```{r, echo = FALSE}
# Inverse RT
ggplot(rt_words_1_cmpl, aes(x = Log10BF_std, y = InvRT, color = lang_type_ortho)) +
  stat_smooth(method = "lm", se = TRUE) +
  labs(title = "Interaction: Log10BF × Language Type",
       x = "Log10BF (standardized)", y = "Inverse RT (1/RT)") +
  scale_color_custom() 

```

#### Plotting Latency

To plot predicted values in milliseconds (RT) instead of inverse RT, you must:

	1.	Predict inverse RT values from the model
	
	2.	Back-transform to milliseconds with RT_ms = 1000 / InvRT
	
	3.	Plot the transformed values
	
When using ggeffects (or emmeans) with models fit using afex::mixed(). The mixed() function wraps lmer() from lme4, but the result isn’t always fully compatible with tools like ggeffects because of the extra layers (especially when using Kenward-Roger or parametric bootstrap methods for inference).

Because we are only using mixed() for the Kenward-Roger p-values but don’t need it for prediction, refit our model with lmer():

	
##### Option 1: Collapsed across Family Size

...

```{r, echo = FALSE, fig.width= 3.5}
# Refit the model with lmer() (for prediction only)
library(lme4)
anova_model_lmer <- lmer(
  InvRT ~ Log10BF_std * FS_Split * lang_type_ortho + (1 | SubjID),
  data = rt_words_1_cmpl
)

#Use emmeans with the new model
library(emmeans)
emm_options(pbkrtest.limit = 6000, lmerTest.limit = 6000)
emm <- emmeans(anova_model_lmer,
               ~ Log10BF_std | lang_type_ortho,
               at = list(Log10BF_std = seq(-4, 3, 0.1)),
               cov.reduce = mean  # Average over levels of FS_Split equally
               )
emm_df <- summary(emm, infer = c(TRUE, TRUE)) |> as.data.frame()

# Back-transform to RT (in milliseconds)
emm_df$RT_ms <- 1 / emm_df$emmean
emm_df$lower_ms <- 1 / emm_df$upper.CL  # Remember: upper InvRT = lower RT
emm_df$upper_ms <- 1 / emm_df$lower.CL

# plot with ggplot2:
p1 <- ggplot(emm_df, aes(x = Log10BF_std, y = RT_ms, color = lang_type_ortho)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower_ms, ymax = upper_ms, 
                  fill = lang_type_ortho), alpha = 0.2, color = NA) +
  labs(y = "Estimated RT (ms)", x = "Log10BF (standardized)",
       title = "c",
       subtitle = "Collapsed Across Morphological Family Size") +
  scale_color_custom() +
  scale_fill_custom() 
p1
```

##### Option 2: LogBR x Language Type as a function of FS

...   
   
```{r, echo = FALSE, fig.width=7}
library(lme4)
library(ggeffects)

anova_model_lmer <- lmer(
  InvRT ~ Log10BF_std * FS_Split * lang_type_ortho + (1 | SubjID),
  data = rt_words_1_cmpl
)


# Get predicted inverse RTs across the range of Log10BF_std. This returns a data frame with predicted values
#pred_df <- ggpredict(anova_model_lmer, terms = c("Log10BF_std [all]", "lang_type_ortho"))
pred_df_L <- ggeffects::ggpredict(anova_model_lmer, terms = c("Log10BF_std", "lang_type_ortho"), condition = c(FS_Split = "L"))
pred_df_S <- ggeffects::ggpredict(anova_model_lmer, terms = c("Log10BF_std", "lang_type_ortho"), condition = c(FS_Split = "S"))

# Convert predicted inverse RT to RT in milliseconds
# Note: When converting from inverse RT to RT, the direction of the confidence interval flips.


pred_df_L$predicted_RT_ms <- 1 / pred_df_L$predicted
pred_df_L$conf.low_ms <- 1 / pred_df_L$conf.high  # Inversion: upper in InvRT → lower in RT
pred_df_L$conf.high_ms <- 1 / pred_df_L$conf.low  # Inversion: lower in InvRT → upper in RT

pred_df_S$predicted_RT_ms <- 1 / pred_df_S$predicted
pred_df_S$conf.low_ms <- 1 / pred_df_S$conf.high  # Inversion: upper in InvRT → lower in RT
pred_df_S$conf.high_ms <- 1 / pred_df_S$conf.low  # Inversion: lower in InvRT → upper in RT


# Plot Large Family Size using ggplot2
p2<- ggplot(pred_df_L, aes(x = x, y = predicted_RT_ms, color = group)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = conf.low_ms, ymax = conf.high_ms, fill = group), alpha = 0.2, color = NA) +
  labs(
    x = "Log10BF (standardized)",
    y = "Predicted RT (ms)",
    color = "Language Type",
    fill = "Language Type",
    title = "Predicted RT by Language Type",
    subtitle = "Large Morphological Family Size"
  ) +
  scale_color_custom() +
  scale_fill_custom() 

# Plot Small Family Size using ggplot2
p3<- ggplot(pred_df_S, aes(x = x, y = predicted_RT_ms, color = group)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = conf.low_ms, ymax = conf.high_ms, fill = group), alpha = 0.2, color = NA) +
  labs(
    x = "Log10BF (standardized)",
    y = "Predicted RT (ms)",
    color = "Language Type",
    fill = "Language Type",
    title = "Predicted RT by Language Type",
    subtitle = "Small Morphological Family Size"
  ) +
  scale_color_custom() +
  scale_fill_custom()

library(cowplot)
plot_grid(p2, p3, ncol = 2)
```


##### Option 3: LogBR x Language Type as a function of FS (Faceted Plot)

...

```{r, echo = FALSE, fig.width=7}
# Estimate marginal means across full range of Log10BF_std, by FS_Split and lang_type_ortho
emm <- emmeans(
  anova_model_lmer,
  ~ Log10BF_std | lang_type_ortho * FS_Split,
  at = list(Log10BF_std = seq(-4, 2.1, 0.1)),
  weights = "equal"  # Optional: average over any remaining factors
)
emm_df <- summary(emm, infer = c(TRUE, TRUE)) |> as.data.frame()

# Back-transform to RT
emm_df$RT_ms <- 1 / emm_df$emmean
emm_df$lower_ms <- 1 / emm_df$upper.CL
emm_df$upper_ms <- 1 / emm_df$lower.CL

# Plot, faceted by FS_Split
ggplot(emm_df, aes(x = Log10BF_std, y = RT_ms, color = lang_type_ortho)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower_ms, ymax = upper_ms, fill = lang_type_ortho), alpha = 0.2, color = NA) +
  facet_wrap(~ FS_Split) +
  labs(y = "Estimated RT (ms)", x = "Log10BF (standardized)",
       title = "Predicted RT by Language Type and FS Split") +
  scale_color_custom() +
  scale_fill_custom() 
```

#### Interpret Interactions

##### Contrast Slopes
```{r}
# Marginal trends (i.e., slopes of Log10BF for each language group)
emtrends(anova_model_1, ~ lang_type_ortho, var = "Log10BF_std")
# Formal contrast of slopes
emtrends(anova_model_1, pairwise ~ lang_type_ortho, var = "Log10BF_std")
```

##### Get ms estimates
```{r}
library(emmeans)

# Estimate inverse RT at mean frequency for each group
emm <- emmeans(anova_model_lmer, ~ lang_type_ortho, at = list(Log10BF_std = 0))
emm_df <- as.data.frame(emm)

# Back-transform to ms
emm_df$RT_ms <- 1 / emm_df$emmean

print(emm_df)
```





## ANOVA Non-Words

Use `complete.cases()` to find which rows had missing data in the model-relevant variables:
```{r, echo=FALSE, results = "hide"}
# Specify only the variables used in the model
model_vars <- c("response_time", "InvRT", "Dim.2","SubjID")

# Identify incomplete rows cohort 1
incomplete_cases_1 <- rt_nwords_1[!complete.cases(rt_nwords_1[, model_vars]), ]
rt_nwords_1_cmpl <- rt_nwords_1[complete.cases(rt_nwords_1[, model_vars]), ]
# View them
print(incomplete_cases_1)

# str(rt_nwords_1_cmpl)
```

### Standardize the predictors

```{r}

rt_nwords_1_cmpl$LogBF_std <- as.numeric(scale(rt_nwords_1_cmpl$LogBF, center = TRUE, scale = TRUE))
rt_nwords_1_cmpl$FS_std <- as.numeric(scale(rt_nwords_1_cmpl$FS, center = TRUE, scale = TRUE))
rt_nwords_1_cmpl$BF_std <- as.numeric(scale(rt_nwords_1_cmpl$BF, center = TRUE, scale = TRUE))
rt_nwords_1_cmpl$Dim.2_std <- as.numeric(scale(rt_nwords_1_cmpl$Dim.2, center = TRUE, scale = TRUE))
```


### Anova with Continuous Log10BF

```{r}
anova_model_2 <- mixed(
  InvRT ~ LogBF_std * FS_Split * lang_type_ortho + (1  | SubjID),
  data = rt_nwords_1_cmpl,
  method = "KR"
)
anova_model_2
summary(anova_model_2)
```


#### Main Findings:

|                     Effect|         df |       F |p.value |
|---------------------------|------------|---------|--------|
|                Log10BF_std| 1, 4599.88 |18.20 ***|   <.001|

	
Data show that as Log10BF increases (e.g., more frequent or predictable words), processing becomes faster (inverse RT goes up → RT goes down). 

Statistical models were fit using inverse response time (1/RT) to capture processing speed, but all reported means and figures are back-transformed to milliseconds for interpretability.


#### Follow up analyses

##### Report Estimated Trend (Slope) for LogBF
```{r}
emtrends(anova_model_2, ~1, var = "LogBF_std")
```

##### Probe the Marginal LogBF × FS_Split Interaction

```{r}
# estimate the slope of LogBF at each level of FS_Split:
emtrends(anova_model_2, ~ FS_Split, var = "LogBF_std")

# compare the two trends:
emtrends(anova_model_2, pairwise ~ FS_Split, var = "LogBF_std")

# Estimate marginal means of inverse RT at LogBF_std = 0
emm <- emmeans(anova_model_2, ~ FS_Split, at = list(LogBF_std = 0))
emm_df <- as.data.frame(emm)

# Back-transform to milliseconds
emm_df$RT_ms <- 1 / emm_df$emmean
emm_df$CI_low_ms <- 1 / emm_df$upper.CL  # Note: upper bound of InvRT → lower RT
emm_df$CI_high_ms <- 1 / emm_df$lower.CL  # lower bound of InvRT → upper RT
print(emm_df)
```

#### Plots

Plotting Processing Efficiency

```{r, echo = FALSE}
# Inverse RT
ggplot(rt_nwords_1_cmpl, aes(x = LogBF_std, y = InvRT, color = lang_type_ortho)) +
  stat_smooth(method = "lm", se = TRUE) +
  labs(title = "Interaction: LogBF × Language Type",
       x = "LogBF (standardized)", y = "Inverse RT (1/RT)") +
  theme_minimal()  +
  scale_color_custom() +
  scale_fill_custom()

```

#### Plotting Latency

To plot predicted values in milliseconds (RT) instead of inverse RT, you must:
	1.	Predict inverse RT values from the model
	2.	Back-transform to milliseconds with RT_ms = 1000 / InvRT
	3.	Plot the transformed values
	
When using ggeffects (or emmeans) with models fit using afex::mixed(). The mixed() function wraps lmer() from lme4, but the result isn’t always fully compatible with tools like ggeffects because of the extra layers (especially when using Kenward-Roger or parametric bootstrap methods for inference).

Because we are only using mixed() for the Kenward-Roger p-values but don’t need it for prediction, refit our model with lmer():

##### Option 1: Collapsed across Family Size
```{r, echo = FALSE}
# Refit the model with lmer() (for prediction only)
library(lme4)
anova_model_lmer <- lmer(
  InvRT ~ LogBF_std * FS_Split * lang_type_ortho + (1 | SubjID),
  data = rt_nwords_1_cmpl
)

#Use emmeans with the new model
library(emmeans)
emm_options(pbkrtest.limit = 6000, lmerTest.limit = 6000)
emm <- emmeans(anova_model_lmer,
               ~ LogBF_std | lang_type_ortho,
               at = list(LogBF_std = seq(-4, 3, 0.1)),
               cov.reduce = mean  # Average over levels of FS_Split equally
               )
emm_df <- summary(emm, infer = c(TRUE, TRUE)) |> as.data.frame()

# Back-transform to RT (in milliseconds)
emm_df$RT_ms <- 1000 / emm_df$emmean
emm_df$lower_ms <- 1000 / emm_df$upper.CL  # Remember: upper InvRT = lower RT
emm_df$upper_ms <- 1000 / emm_df$lower.CL

# plot with ggplot2:
ggplot(emm_df, aes(x = LogBF_std, y = RT_ms, color = lang_type_ortho)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower_ms, ymax = upper_ms, 
                  fill = lang_type_ortho), alpha = 0.2, color = NA) +
  labs(y = "Estimated RT (ms)", x = "LogBF (standardized)", 
       title = "Predicted RT by Language Type") +
  theme_minimal() +
  scale_color_custom() +
  scale_fill_custom()
```

##### Option 2: LogBR x Language Type as a function of FS
```{r, echo = FALSE}
library(lme4)
library(ggeffects)

anova_model_lmer <- lmer(
  InvRT ~ LogBF_std * FS_Split * lang_type_ortho + (1 | SubjID),
  data = rt_nwords_1_cmpl
)


# Get predicted inverse RTs across the range of Log10BF_std. This returns a data frame with predicted values
#pred_df <- ggpredict(anova_model_lmer, terms = c("Log10BF_std [all]", "lang_type_ortho"))
pred_df_L <- ggeffects::ggpredict(anova_model_lmer, terms = c("LogBF_std", "lang_type_ortho"), condition = c(FS_Split = "L"))
pred_df_S <- ggeffects::ggpredict(anova_model_lmer, terms = c("LogBF_std", "lang_type_ortho"), condition = c(FS_Split = "S"))


# Convert predicted inverse RT to RT in milliseconds
# Note: When converting from inverse RT to RT, the direction of the confidence interval flips.
pred_df_L$predicted_RT_ms <- 1000 / pred_df_L$predicted
pred_df_L$conf.low_ms <- 1000 / pred_df_L$conf.high  # Inversion: upper in InvRT → lower in RT
pred_df_L$conf.high_ms <- 1000 / pred_df_L$conf.low  # Inversion: lower in InvRT → upper in RT

pred_df_S$predicted_RT_ms <- 1000 / pred_df_S$predicted
pred_df_S$conf.low_ms <- 1000 / pred_df_S$conf.high  # Inversion: upper in InvRT → lower in RT
pred_df_S$conf.high_ms <- 1000 / pred_df_S$conf.low  # Inversion: lower in InvRT → upper in RT


# Plot Large Family Size using ggplot2
ggplot(pred_df_L, aes(x = x, y = predicted_RT_ms, color = group)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = conf.low_ms, ymax = conf.high_ms, fill = group), alpha = 0.2, color = NA) +
  labs(
    x = "LogBF (standardized)",
    y = "Predicted RT (ms)",
    color = "Language Type",
    fill = "Language Type",
    title = "Effect of LogBF × Language Type on RT: Large Family Size"
  ) +
  theme_minimal() +
  scale_color_custom() +
  scale_fill_custom()

# Plot Small Family Size using ggplot2
ggplot(pred_df_S, aes(x = x, y = predicted_RT_ms, color = group)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = conf.low_ms, ymax = conf.high_ms, fill = group), alpha = 0.2, color = NA) +
  labs(
    x = "LogBF (standardized)",
    y = "Predicted RT (ms)",
    color = "Language Type",
    fill = "Language Type",
    title = "Effect of LogBF × Language Type on RT: Small Family Size"
  ) +
  theme_minimal() +
  scale_color_custom() +
  scale_fill_custom()
```


##### Option 3: LogBR x Language Type as a function of FS (Faceted Plot)
```{r, echo = FALSE}
# Estimate marginal means across full range of Log10BF_std, by FS_Split and lang_type_ortho
emm <- emmeans(
  anova_model_lmer,
  ~ LogBF_std | lang_type_ortho * FS_Split,
  at = list(LogBF_std = seq(-4, 2.1, 0.1)),
  weights = "equal"  # Optional: average over any remaining factors
)
emm_df <- summary(emm, infer = c(TRUE, TRUE)) |> as.data.frame()

# Back-transform to RT
emm_df$RT_ms <- 1000 / emm_df$emmean
emm_df$lower_ms <- 1000 / emm_df$upper.CL
emm_df$upper_ms <- 1000 / emm_df$lower.CL

# Plot, faceted by FS_Split
ggplot(emm_df, aes(x = LogBF_std, y = RT_ms, color = lang_type_ortho)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower_ms, ymax = upper_ms, fill = lang_type_ortho), alpha = 0.2, color = NA) +
  facet_wrap(~ FS_Split) +
  labs(y = "Estimated RT (ms)", x = "LogBF (standardized)",
       title = "Predicted RT by Language Type and FS Split") +
  theme_minimal()  +
  scale_color_custom() +
  scale_fill_custom()
```



